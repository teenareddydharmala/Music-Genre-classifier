{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a66ee8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎵 Genres found: ['blues', 'classical', 'country', 'disco', 'hiphop', 'jazz', 'metal', 'pop', 'reggae', 'rock']\n",
      "⚠️ Error processing F:\\projects\\personal projects\\Music-Genre-classifier\\data\\genre\\blues\\blues.00000.wav: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 4 has 2 dimension(s)\n",
      "⚠️ Error processing F:\\projects\\personal projects\\Music-Genre-classifier\\data\\genre\\blues\\blues.00001.wav: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 4 has 2 dimension(s)\n",
      "⚠️ Error processing F:\\projects\\personal projects\\Music-Genre-classifier\\data\\genre\\blues\\blues.00002.wav: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 4 has 2 dimension(s)\n",
      "⚠️ Error processing F:\\projects\\personal projects\\Music-Genre-classifier\\data\\genre\\blues\\blues.00003.wav: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 4 has 2 dimension(s)\n",
      "⚠️ Error processing F:\\projects\\personal projects\\Music-Genre-classifier\\data\\genre\\blues\\blues.00004.wav: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 4 has 2 dimension(s)\n",
      "⚠️ Error processing F:\\projects\\personal projects\\Music-Genre-classifier\\data\\genre\\blues\\blues.00005.wav: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 4 has 2 dimension(s)\n",
      "⚠️ Error processing F:\\projects\\personal projects\\Music-Genre-classifier\\data\\genre\\blues\\blues.00006.wav: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 4 has 2 dimension(s)\n",
      "⚠️ Error processing F:\\projects\\personal projects\\Music-Genre-classifier\\data\\genre\\blues\\blues.00007.wav: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 4 has 2 dimension(s)\n",
      "⚠️ Error processing F:\\projects\\personal projects\\Music-Genre-classifier\\data\\genre\\blues\\blues.00008.wav: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 4 has 2 dimension(s)\n",
      "⚠️ Error processing F:\\projects\\personal projects\\Music-Genre-classifier\\data\\genre\\blues\\blues.00009.wav: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 4 has 2 dimension(s)\n",
      "⚠️ Error processing F:\\projects\\personal projects\\Music-Genre-classifier\\data\\genre\\blues\\blues.00010.wav: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 4 has 2 dimension(s)\n",
      "⚠️ Error processing F:\\projects\\personal projects\\Music-Genre-classifier\\data\\genre\\blues\\blues.00011.wav: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 4 has 2 dimension(s)\n",
      "⚠️ Error processing F:\\projects\\personal projects\\Music-Genre-classifier\\data\\genre\\blues\\blues.00012.wav: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 4 has 2 dimension(s)\n",
      "⚠️ Error processing F:\\projects\\personal projects\\Music-Genre-classifier\\data\\genre\\blues\\blues.00013.wav: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 4 has 2 dimension(s)\n",
      "⚠️ Error processing F:\\projects\\personal projects\\Music-Genre-classifier\\data\\genre\\blues\\blues.00014.wav: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 4 has 2 dimension(s)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 63\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m filename.endswith(\u001b[33m\"\u001b[39m\u001b[33m.wav\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m     62\u001b[39m     file_path = os.path.join(genre_path, filename)\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m     data = \u001b[43mextract_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     64\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     65\u001b[39m         features.append(data)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 31\u001b[39m, in \u001b[36mextract_features\u001b[39m\u001b[34m(file_path)\u001b[39m\n\u001b[32m     28\u001b[39m mfcc_mean = np.mean(mfcc.T, axis=\u001b[32m0\u001b[39m)\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# Chroma – harmony/melody (like musical chords)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m chroma = \u001b[43mlibrosa\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchroma_stft\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[43m=\u001b[49m\u001b[43msr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m chroma_mean = np.mean(chroma.T, axis=\u001b[32m0\u001b[39m)\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# Spectral Contrast – sharp vs soft tones\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\librosa\\feature\\spectral.py:1275\u001b[39m, in \u001b[36mchroma_stft\u001b[39m\u001b[34m(y, sr, S, norm, n_fft, hop_length, win_length, window, center, pad_mode, tuning, n_chroma, **kwargs)\u001b[39m\n\u001b[32m   1262\u001b[39m S, n_fft = _spectrogram(\n\u001b[32m   1263\u001b[39m     y=y,\n\u001b[32m   1264\u001b[39m     S=S,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1271\u001b[39m     pad_mode=pad_mode,\n\u001b[32m   1272\u001b[39m )\n\u001b[32m   1274\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tuning \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1275\u001b[39m     tuning = \u001b[43mestimate_tuning\u001b[49m\u001b[43m(\u001b[49m\u001b[43mS\u001b[49m\u001b[43m=\u001b[49m\u001b[43mS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[43m=\u001b[49m\u001b[43msr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbins_per_octave\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_chroma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1277\u001b[39m \u001b[38;5;66;03m# Get the filter bank\u001b[39;00m\n\u001b[32m   1278\u001b[39m chromafb = filters.chroma(\n\u001b[32m   1279\u001b[39m     sr=sr, n_fft=n_fft, tuning=tuning, n_chroma=n_chroma, **kwargs\n\u001b[32m   1280\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\librosa\\core\\pitch.py:93\u001b[39m, in \u001b[36mestimate_tuning\u001b[39m\u001b[34m(y, sr, S, n_fft, resolution, bins_per_octave, **kwargs)\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mestimate_tuning\u001b[39m(\n\u001b[32m     27\u001b[39m     *,\n\u001b[32m     28\u001b[39m     y: Optional[np.ndarray] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     34\u001b[39m     **kwargs: Any,\n\u001b[32m     35\u001b[39m ) -> \u001b[38;5;28mfloat\u001b[39m:\n\u001b[32m     36\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Estimate the tuning of an audio time series or spectrogram input.\u001b[39;00m\n\u001b[32m     37\u001b[39m \n\u001b[32m     38\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     91\u001b[39m \u001b[33;03m    -0.08000000000000002\u001b[39;00m\n\u001b[32m     92\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m     pitch, mag = \u001b[43mpiptrack\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[43m=\u001b[49m\u001b[43msr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mS\u001b[49m\u001b[43m=\u001b[49m\u001b[43mS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_fft\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_fft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     95\u001b[39m     \u001b[38;5;66;03m# Only count magnitude where frequency is > 0\u001b[39;00m\n\u001b[32m     96\u001b[39m     pitch_mask = pitch > \u001b[32m0\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\librosa\\core\\pitch.py:334\u001b[39m, in \u001b[36mpiptrack\u001b[39m\u001b[34m(y, sr, S, n_fft, hop_length, fmin, fmax, threshold, win_length, window, center, pad_mode, ref)\u001b[39m\n\u001b[32m    331\u001b[39m dskew = \u001b[32m0.5\u001b[39m * avg * shift\n\u001b[32m    333\u001b[39m \u001b[38;5;66;03m# Pre-allocate output\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m334\u001b[39m pitches = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzeros_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    335\u001b[39m mags = np.zeros_like(S)\n\u001b[32m    337\u001b[39m \u001b[38;5;66;03m# Clip to the viable frequency range\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\numpy\\_core\\numeric.py:133\u001b[39m, in \u001b[36mzeros_like\u001b[39m\u001b[34m(a, dtype, order, subok, shape, device)\u001b[39m\n\u001b[32m    131\u001b[39m \u001b[38;5;66;03m# needed instead of a 0 to get same result as zeros for string dtypes\u001b[39;00m\n\u001b[32m    132\u001b[39m z = zeros(\u001b[32m1\u001b[39m, dtype=res.dtype)\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m \u001b[43mmultiarray\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcopyto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcasting\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43munsafe\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Day 2 - Improved Music Genre Classification with More Features + KNN\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from joblib import dump, load\n",
    "\n",
    "# 🔹 Dataset path - update this to your dataset location\n",
    "DATASET_PATH = r\"F:\\projects\\personal projects\\Music-Genre-classifier\\data\\genre\"\n",
    "\n",
    "# 🔹 Get list of genres (folder names)\n",
    "genres = os.listdir(DATASET_PATH)\n",
    "print(\"🎵 Genres found:\", genres)\n",
    "\n",
    "# ✅ Function to extract multiple features from an audio file\n",
    "def extract_features(file_path):\n",
    "    try:\n",
    "        y, sr = librosa.load(file_path, duration=15)\n",
    "        \n",
    "        # MFCC (Mel Frequency Cepstral Coefficients) – voice texture\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "        mfcc_mean = np.mean(mfcc.T, axis=0)\n",
    "        \n",
    "        # Chroma – harmony/melody (like musical chords)\n",
    "        chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "        chroma_mean = np.mean(chroma.T, axis=0)\n",
    "\n",
    "        # Spectral Contrast – sharp vs soft tones\n",
    "        contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
    "        contrast_mean = np.mean(contrast.T, axis=0)\n",
    "\n",
    "        # Zero Crossing Rate – how noisy the signal is\n",
    "        zcr = librosa.feature.zero_crossing_rate(y)\n",
    "        zcr_mean = np.mean(zcr.T, axis=0)\n",
    "\n",
    "        # Tempo – speed of the beat\n",
    "        tempo, _ = librosa.beat.beat_track(y=y, sr=sr)\n",
    "        tempo_feature = np.array([tempo])\n",
    "\n",
    "        # 🧠 Combine all features into one array (make sure all are 1D arrays)\n",
    "        features = np.hstack([mfcc_mean, chroma_mean, contrast_mean, zcr_mean, tempo_feature])\n",
    "        return features\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error processing {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# 🔹 Create features and labels\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "for genre in genres:\n",
    "    genre_path = os.path.join(DATASET_PATH, genre)\n",
    "    for filename in os.listdir(genre_path):\n",
    "        if filename.endswith(\".wav\"):\n",
    "            file_path = os.path.join(genre_path, filename)\n",
    "            data = extract_features(file_path)\n",
    "            if data is not None:\n",
    "                features.append(data)\n",
    "                labels.append(genre)\n",
    "\n",
    "# ✅ Convert to numpy arrays\n",
    "X = np.array(features)\n",
    "y = np.array(labels)\n",
    "\n",
    "print(\"✅ Feature matrix shape:\", X.shape)\n",
    "print(\"✅ Labels shape:\", y.shape)\n",
    "\n",
    "# 🧼 Scale features so KNN works better\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# ✂️ Train/Test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 🤖 Train KNN model\n",
    "model = KNeighborsClassifier(n_neighbors=5)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 🔍 Predict\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 📊 Evaluation\n",
    "print(\"\\n✅ Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\n📄 Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# 📉 Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred, labels=model.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
    "disp.plot(xticks_rotation='vertical')\n",
    "plt.title(\"🎯 Confusion Matrix\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 🔹 Save model to disk for later use\n",
    "dump(model, 'knn_music_genre_model.joblib')\n",
    "print(\"✅ Model saved successfully!\")\n",
    "\n",
    "# ✅ Test your own songs\n",
    "def predict_genre_for_song(song_path):\n",
    "    # Extract features for your song (same as before)\n",
    "    features = extract_features(song_path)\n",
    "    \n",
    "    # Check if features were successfully extracted\n",
    "    if features is not None:\n",
    "        # Scale features using the same scaler\n",
    "        features_scaled = scaler.transform([features])\n",
    "        \n",
    "        # Predict genre using the trained model\n",
    "        predicted_genre = model.predict(features_scaled)\n",
    "        \n",
    "        print(f\"🎵 The predicted genre for '{song_path}' is: {predicted_genre[0]}\")\n",
    "    else:\n",
    "        print(f\"⚠️ Could not extract features for {song_path}\")\n",
    "\n",
    "# 📂 Loop through your list of songs and predict their genres\n",
    "my_songs_folder = './my_songs/'  # Folder where your songs are located\n",
    "for song in os.listdir(my_songs_folder):\n",
    "    if song.endswith(\".wav\"):\n",
    "        song_path = os.path.join(my_songs_folder, song)\n",
    "        predict_genre_for_song(song_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
